{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Config Manager data to the Azure Database\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "-  Python dependencies:\n",
    "    - pandas : 2.0.0,\n",
    "    - json   : 2.0.9,\n",
    "    - pyarrow: 12.0.1,\n",
    "    - pyodbc : 4.0.39,\n",
    "    - azure  : 5.0.0\n",
    "- `fun.json` for access credentials\n",
    "- `/create_sql` folder for SQL code to create tables\n",
    "\n",
    "I assigned us all an equal number of tables to load in the Historic Config Manager Summary excel document in our shared google drive. The names of the parquet files in Azure Blob Storage are also included there.\n",
    "See the link below: https://docs.google.com/spreadsheets/d/1GTahzraMPXh9RTNQHnqzBrZaee4qBTkjZV6v58WjhfM/edit?usp=sharing\n",
    "\n",
    "\n",
    "\n",
    "### Section 1 - Workflow Instructions \n",
    "\n",
    "1. Assemble prerequisites. Ensure the python dependencies listed above are installed in your working environment. Make a subdirectory in your working directory called `/assets` and place the `fun.json` file there.\n",
    "\n",
    "2. Download the config manager parquet files from Azure Blob Storage. Use the code in section 2. Credentials needed to access the storage container are provided in `fun.json`. \n",
    "\n",
    "3. Create the SQL table in the Azure database for each table. Connect to the Azure SQL Database using DBeaver or another preferred database development environment. Run the SQL code for the corresponding table in `/assets/create_sql` to create each config manager database table. \n",
    "\n",
    "4. Load the SQL table with data from the parquet file. Use the code in section 3. Feel free to optimize this code to make the load process faster!\n",
    "\n",
    "5. Repeat steps 2 through 4 for all Config manager tables that were assigned.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 - Download parquet files from Azure Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T17:37:02.804897739Z",
     "start_time": "2023-07-10T17:37:02.229632845Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import pyodbc\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Read in credentials\n",
    "with open('./assets/fun.json') as f:\n",
    "    cred = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T17:42:48.033482571Z",
     "start_time": "2023-07-10T17:42:47.982009745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 1.4940903186798096 seconds to download Persist_USER_DISC.parquet\n"
     ]
    }
   ],
   "source": [
    "def download_blob(blob_name, local_file_name):\n",
    "    '''\n",
    "    Downloads the parquet file from the blob container.\n",
    "    '''\n",
    "\n",
    "    # Declare variables\n",
    "    STORAGEACCOUNTURL= cred['in_the_sun']\n",
    "    STORAGEACCOUNTKEY= cred['fun']\n",
    "    LOCALFILENAME= local_file_name\n",
    "    CONTAINERNAME= 'configmanagertest1'\n",
    "    BLOBNAME= blob_name\n",
    "\n",
    "    # Download from blob\n",
    "    t1=time.time()\n",
    "    blob_service_client_instance = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\n",
    "    blob_client_instance = blob_service_client_instance.get_blob_client(CONTAINERNAME, BLOBNAME, snapshot=None)\n",
    "    with open(LOCALFILENAME, \"wb\") as my_blob:\n",
    "        blob_data = blob_client_instance.download_blob()\n",
    "        blob_data.readinto(my_blob)\n",
    "    t2=time.time()\n",
    "    print((\"It takes %s seconds to download \"+BLOBNAME) % (t2 - t1))\n",
    "\n",
    "# Call the function\n",
    "download_blob(blob_name='Persist_USER_DISC.parquet', local_file_name='./assets/UserDisc.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T17:42:50.001332272Z",
     "start_time": "2023-07-10T17:42:48.515342638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         RWB_User_DISC_ID  RWB_ETL_EVENT_DESTINATION_IDENTIFIER   \n0                       1                                   874  \\\n1                       2                                   874   \n2                       3                                   874   \n3                       4                                   874   \n4                       5                                   874   \n...                   ...                                   ...   \n1088322           1088323                                 11237   \n1088323           1088324                                 11237   \n1088324           1088325                                 11237   \n1088325           1088326                                 11237   \n1088326           1088327                                 11237   \n\n               RWB_CREATE_TIMESTAMP RWB_EFFECTIVE_DATE     ItemKey   \n0        2023-01-19 09:25:25 -06:00         2023-01-19  2063597632  \\\n1        2023-01-19 09:25:25 -06:00         2023-01-19  2063597633   \n2        2023-01-19 09:25:25 -06:00         2023-01-19  2063597634   \n3        2023-01-19 09:25:25 -06:00         2023-01-19  2063597635   \n4        2023-01-19 09:25:25 -06:00         2023-01-19  2063597636   \n...                             ...                ...         ...   \n1088322  2023-07-10 08:04:25 -05:00         2023-07-10  2063609675   \n1088323  2023-07-10 08:04:25 -05:00         2023-07-10  2063609676   \n1088324  2023-07-10 08:04:25 -05:00         2023-07-10  2063609677   \n1088325  2023-07-10 08:04:25 -05:00         2023-07-10  2063609678   \n1088326  2023-07-10 08:04:25 -05:00         2023-07-10  2063609679   \n\n         DiscArchKey  User_Name0 Network_Operating_System0 Windows_NT_Domain0   \n0                  4       11952                Windows NT                 US  \\\n1                  4          95                Windows NT                 US   \n2                  4        6685                Windows NT                 US   \n3                  4        9800                Windows NT                 US   \n4                  4        8918                Windows NT                 US   \n...              ...         ...                       ...                ...   \n1088322            4       18301                Windows NT                 US   \n1088323            4       18302                Windows NT                 US   \n1088324            4       18303                Windows NT                 US   \n1088325            4       18304                Windows NT                 US   \n1088326            4        3274                Windows NT                 US   \n\n        Full_Domain_Name0                                              SID0   \n0          us.rwbaird.com  S-1-5-21-3370485269-2891970317-3398629184-586247  \\\n1          us.rwbaird.com  S-1-5-21-3370485269-2891970317-3398629184-597336   \n2          us.rwbaird.com  S-1-5-21-3370485269-2891970317-3398629184-597335   \n3          us.rwbaird.com  S-1-5-21-3370485269-2891970317-3398629184-587231   \n4          us.rwbaird.com  S-1-5-21-3370485269-2891970317-3398629184-587230   \n...                   ...                                               ...   \n1088322    US.RWBAIRD.COM  S-1-5-21-3370485269-2891970317-3398629184-655685   \n1088323    US.RWBAIRD.COM  S-1-5-21-3370485269-2891970317-3398629184-655686   \n1088324    US.RWBAIRD.COM  S-1-5-21-3370485269-2891970317-3398629184-656111   \n1088325    US.RWBAIRD.COM  S-1-5-21-3370485269-2891970317-3398629184-653055   \n1088326    US.RWBAIRD.COM  S-1-5-21-3370485269-2891970317-3398629184-641936   \n\n                 Creation_Date0  \n0       2020-08-27 14:45:33.267  \n1       2020-08-27 14:45:33.283  \n2       2020-08-27 14:45:33.283  \n3       2020-08-27 14:45:33.300  \n4       2020-08-27 14:45:33.300  \n...                         ...  \n1088322 2023-07-08 02:25:02.707  \n1088323 2023-07-08 02:25:02.707  \n1088324 2023-07-08 02:50:03.960  \n1088325 2023-07-08 02:50:03.960  \n1088326 2023-07-08 02:50:03.960  \n\n[1088327 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RWB_User_DISC_ID</th>\n      <th>RWB_ETL_EVENT_DESTINATION_IDENTIFIER</th>\n      <th>RWB_CREATE_TIMESTAMP</th>\n      <th>RWB_EFFECTIVE_DATE</th>\n      <th>ItemKey</th>\n      <th>DiscArchKey</th>\n      <th>User_Name0</th>\n      <th>Network_Operating_System0</th>\n      <th>Windows_NT_Domain0</th>\n      <th>Full_Domain_Name0</th>\n      <th>SID0</th>\n      <th>Creation_Date0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>874</td>\n      <td>2023-01-19 09:25:25 -06:00</td>\n      <td>2023-01-19</td>\n      <td>2063597632</td>\n      <td>4</td>\n      <td>11952</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>us.rwbaird.com</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-586247</td>\n      <td>2020-08-27 14:45:33.267</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>874</td>\n      <td>2023-01-19 09:25:25 -06:00</td>\n      <td>2023-01-19</td>\n      <td>2063597633</td>\n      <td>4</td>\n      <td>95</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>us.rwbaird.com</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-597336</td>\n      <td>2020-08-27 14:45:33.283</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>874</td>\n      <td>2023-01-19 09:25:25 -06:00</td>\n      <td>2023-01-19</td>\n      <td>2063597634</td>\n      <td>4</td>\n      <td>6685</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>us.rwbaird.com</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-597335</td>\n      <td>2020-08-27 14:45:33.283</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>874</td>\n      <td>2023-01-19 09:25:25 -06:00</td>\n      <td>2023-01-19</td>\n      <td>2063597635</td>\n      <td>4</td>\n      <td>9800</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>us.rwbaird.com</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-587231</td>\n      <td>2020-08-27 14:45:33.300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>874</td>\n      <td>2023-01-19 09:25:25 -06:00</td>\n      <td>2023-01-19</td>\n      <td>2063597636</td>\n      <td>4</td>\n      <td>8918</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>us.rwbaird.com</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-587230</td>\n      <td>2020-08-27 14:45:33.300</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1088322</th>\n      <td>1088323</td>\n      <td>11237</td>\n      <td>2023-07-10 08:04:25 -05:00</td>\n      <td>2023-07-10</td>\n      <td>2063609675</td>\n      <td>4</td>\n      <td>18301</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>US.RWBAIRD.COM</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-655685</td>\n      <td>2023-07-08 02:25:02.707</td>\n    </tr>\n    <tr>\n      <th>1088323</th>\n      <td>1088324</td>\n      <td>11237</td>\n      <td>2023-07-10 08:04:25 -05:00</td>\n      <td>2023-07-10</td>\n      <td>2063609676</td>\n      <td>4</td>\n      <td>18302</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>US.RWBAIRD.COM</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-655686</td>\n      <td>2023-07-08 02:25:02.707</td>\n    </tr>\n    <tr>\n      <th>1088324</th>\n      <td>1088325</td>\n      <td>11237</td>\n      <td>2023-07-10 08:04:25 -05:00</td>\n      <td>2023-07-10</td>\n      <td>2063609677</td>\n      <td>4</td>\n      <td>18303</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>US.RWBAIRD.COM</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-656111</td>\n      <td>2023-07-08 02:50:03.960</td>\n    </tr>\n    <tr>\n      <th>1088325</th>\n      <td>1088326</td>\n      <td>11237</td>\n      <td>2023-07-10 08:04:25 -05:00</td>\n      <td>2023-07-10</td>\n      <td>2063609678</td>\n      <td>4</td>\n      <td>18304</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>US.RWBAIRD.COM</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-653055</td>\n      <td>2023-07-08 02:50:03.960</td>\n    </tr>\n    <tr>\n      <th>1088326</th>\n      <td>1088327</td>\n      <td>11237</td>\n      <td>2023-07-10 08:04:25 -05:00</td>\n      <td>2023-07-10</td>\n      <td>2063609679</td>\n      <td>4</td>\n      <td>3274</td>\n      <td>Windows NT</td>\n      <td>US</td>\n      <td>US.RWBAIRD.COM</td>\n      <td>S-1-5-21-3370485269-2891970317-3398629184-641936</td>\n      <td>2023-07-08 02:50:03.960</td>\n    </tr>\n  </tbody>\n</table>\n<p>1088327 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in parquet file as DataFrame.\n",
    "df = pd.read_parquet('./assets/UserDisc.parquet', engine='pyarrow')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T17:42:51.544984298Z",
     "start_time": "2023-07-10T17:42:51.302619456Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace empty strings with None.\n",
    "df = df.applymap(lambda x: None if x == \"\" else x)\n",
    "count = (df.eq(\"\")).sum().sum()\n",
    "print(\"Number of empty strings:\", count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace any np.inf values with np.nan.\n",
    "df.replace({np.inf: np.nan, -np.inf: np.nan}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pq = pq.where(pd.notnull(pq), None)\n",
    "# pq.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert float64 columns to int.\n",
    "float_columns = df.select_dtypes(include=['float64']).columns\n",
    "df[float_columns] = df[float_columns].fillna(0)\n",
    "df[float_columns] = df[float_columns].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save out parquet file.\n",
    "df.to_parquet('./assets/BatteryCorrected.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 - Load data to the Azure SQL table"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Make the database table.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Connect to database.\n",
    "1. Connect using SQL editor of choice (DBeaver, DataGrip).\n",
    "2. Select Azure SQL using built-in connection type.\n",
    "3. In pop-up dialog window, enter connection credentials using values from `fun.json` to authenticate.\n",
    "4. Connect to Azure DB.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Add table.\n",
    "1. Find `Tables` subdirectory under `dbo` schema.\n",
    "2. Right-click to open context window. Highlight \"Add...\". Click \"New table\".\n",
    "3. Dialog window appears. Provide SQL template code from `create_sql` directory for the corresponding table.\n",
    "    - Change table name in dialog window to `Persist.Table_Name`.\n",
    "    - You may need to edit the SQL to successfully create the correct table.\n",
    "    - Remove `IDENTITY(1,1)`\n",
    "    - Remove `ON [filegroup]` statement from `WITH` near bottom.\n",
    "    - Change table name to: `dbo.[Persist.Table_Name]`\n",
    "4. Once the table is created, run the below function to push your data to the table.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Upload the DataFrame as a parquet file to the table.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conn string\n",
    "conn_string = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={cred['server']};DATABASE={cred['db']};UID={cred['uid']};PWD={cred['pwd']}\"\n",
    "# Establish a connection to the SQL Server database\n",
    "\n",
    "conn = pyodbc.connect(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_table_v2(conn_obj, table_name, pq_file_name, stop_at):\n",
    "    '''\n",
    "    Loads a full table of data into the table_name of the\n",
    "    connect database in the conn_obj. Uses chunking for an\n",
    "    efficient load.\n",
    "    '''\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = conn_obj.cursor()\n",
    "\n",
    "    # Read in the parquet file\n",
    "    parquet_data = pq.ParquetFile(pq_file_name) # RJ 07/08/2023: Subset .pq here.\n",
    "\n",
    "    # Get the field names from the parquet file schema\n",
    "    pq_field_names = parquet_data.schema_arrow.names\n",
    "    col_tup_str_curr = '(' + ','.join(pq_field_names) +')'\n",
    "\n",
    "    # Get the number of (?) to duplicate in the insert query\n",
    "    num_qs_rep = len(col_tup_str_curr.split(','))\n",
    "\n",
    "    # Make the values string\n",
    "    values_ques_str = ','.join(tuple(['?']*num_qs_rep))\n",
    "\n",
    "    # Define the SQL insert statement\n",
    "    insert_query = \"INSERT INTO \" + table_name + \" \" + col_tup_str_curr + \" VALUES (\" + values_ques_str + \")\"\n",
    "\n",
    "    # Read the Parquet file in chunks\n",
    "    chunk_size = 10000\n",
    "    num_rows = parquet_data.metadata.num_rows\n",
    "    num_chunks = num_rows // chunk_size + 1\n",
    "\n",
    "    # Track the rows loaded during the insert\n",
    "    rows_loaded = 0\n",
    "    track_to_100k = 0\n",
    "\n",
    "    # Process and insert the data in chunks\n",
    "    batch_number = 0\n",
    "    batch_stop = 100 # Break at 1,000,000 rows.\n",
    "    for batch in parquet_data.iter_batches(batch_size=chunk_size):\n",
    "\n",
    "        # Stop after n rows\n",
    "        if rows_loaded == stop_at:\n",
    "            break\n",
    "\n",
    "        # Read the chunk of data from Parquet.\n",
    "        chunk = batch.to_pandas()\n",
    "        # Convert the chunk to a list of tuples.\n",
    "        records = [tuple(row) for row in chunk.itertuples(index=False)]\n",
    "        # Execute the INSERT statement with executemany().\n",
    "        cursor.executemany(insert_query, records)\n",
    "        conn_obj.commit()\n",
    "\n",
    "        # Notify when 100K rows are loaded\n",
    "        rows_loaded = rows_loaded + len(chunk)\n",
    "        track_to_100k = len(chunk) + track_to_100k\n",
    "        if track_to_100k >= 100000:\n",
    "            print(f\"{rows_loaded} number of rows loaded.\")\n",
    "            track_to_100k = 0\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "\n",
    "# Call the function\n",
    "load_table_v2(conn_obj=conn, table_name='dbo.[Persist.BATTERY_DATA]', pq_file_name='assets/BatteryCorrected.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document dependencies in a jupyter notebook\n",
    "# Dependencies for this notebook\n",
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
