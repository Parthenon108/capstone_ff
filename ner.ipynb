{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:45.906845478Z",
     "start_time": "2023-07-12T03:18:45.884672395Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Columns: 118 entries, parent to category\n",
      "dtypes: float64(72), object(46)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r'./DatabaseTableUpload/Appendix_A_Capstone_DataSharingProposal.xlsx', sheet_name='A.25_ServiceNow_Incidents') # Provide path for a single file.\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:46.037155990Z",
     "start_time": "2023-07-12T03:18:45.889272156Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Named Entity Recognition (NER)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sizes: ['sm', 'md', 'lg']<br>\n",
    "Your pipeline must be compatable with your current version of SpaCy.\n",
    "\n",
    "Can download the following on Conda (base) environment:\n",
    "`pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_[SIZE]-[VERSION]/en_core_web_md-[VERSION].tar.gz`\n",
    "\n",
    "Alternatively, in Python:\n",
    "`python -m spacy download en_core_web_sm`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Instantiate a Tokenizer with the default settings for English, including punctuation rules and exceptions.\n",
    "tokenizer = nlp.tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:46.097830586Z",
     "start_time": "2023-07-12T03:18:46.026639266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Assign SpaCy `en_core_web_` as `nlp`.\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "ner = nlp.get_pipe('ner')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:48.513799624Z",
     "start_time": "2023-07-12T03:18:46.088853640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitney Bowes P2000 Series isn't able to connect with network\n",
      "Pitney PROPN compound\n",
      "Bowes PROPN compound\n",
      "P2000 PROPN compound\n",
      "Series PROPN nsubj\n",
      "is AUX ROOT\n",
      "n't PART neg\n",
      "able ADJ acomp\n",
      "to PART aux\n",
      "connect VERB xcomp\n",
      "with ADP prep\n",
      "network NOUN pobj\n"
     ]
    }
   ],
   "source": [
    "# Example of token generation for the first body of text.\n",
    "doc = nlp(df['short_description'][0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_) # Print: token, POS, syntactic dependency."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:48.559396392Z",
     "start_time": "2023-07-12T03:18:48.515605547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Create function to add an article's tokens to `doc_list`.\n",
    "# Tokenize one time, then use that object for the subsequent accumulators.\n",
    "# Returns None many times.\n",
    "doc_list = []\n",
    "def to_doc_list(text):\n",
    "    doc_list.append(nlp(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:48.559792086Z",
     "start_time": "2023-07-12T03:18:48.549171636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0     None\n1     None\n2     None\n3     None\n4     None\n5     None\n6     None\n7     None\n8     None\n9     None\n10    None\n11    None\n12    None\n13    None\n14    None\n15    None\nName: short_description, dtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes time to generate tokens from each cell's fulltext.\n",
    "df['short_description'].apply(to_doc_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.080402354Z",
     "start_time": "2023-07-12T03:18:48.552246994Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0     (Pitney, Bowes, P2000, Series, is, n't, able, ...\n1       (Can, not, connect, to, in, -, office, Desktop)\n2             (Brittany, Tyler, -, Fixed, Income, Desk)\n3     (Break, /, fix, Docking, station, not, providi...\n4     (Baird, TrustDesk, Migration, to, OneDrive, -,...\n5                      (Deposit, Edge, Account, Unlock)\n6     (MFA, Authentication, Loop, -, Unable, to, acc...\n7     (Beta, report, ran, out, of, paper, ., Needs, ...\n8         (Laptop, not, charging, on, Docking, Station)\n9               (Mac, not, connecting, to, Guest, wifi)\n10    (RJ, Edgerly, needs, his, Outlook, inbox, rest...\n11    (Hello, ., My, name, is, spelled, incorrectly,...\n12    (Custom, example, :, Bryce, Townsend, tried, t...\n13    (Custom, example, :, Aditya, Patel, needs, a, ...\n14    (Custom, example, :, Stanislav, Oliynyk, needs...\n15    (Custom, example, :, Parasol, needs, to, have,...\ndtype: object"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign `doc_list` to `doc_series` as a Series object.\n",
    "doc_series = pd.Series(doc_list)\n",
    "doc_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.086783681Z",
     "start_time": "2023-07-12T03:18:49.082799368Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitney Bowes P2000 Series isn't able to connect with network\n",
      "Pitney Bowes P2000 Series is n't able to connect with network \n",
      "\n",
      "Cannot connect to in-office Desktop\n",
      "Can not connect to in- office Desktop \n",
      "\n",
      "Brittany Tyler - Fixed Income Desk\n",
      "<PERSON> <PERSON>- Fixed Income Desk \n",
      "\n",
      "Break/fix Docking station not providing monitor display or network\n",
      "Break / fix Docking station not providing monitor display or network \n",
      "\n",
      "Baird TrustDesk Migration to OneDrive - Error migrating \n",
      "Baird TrustDesk Migration to OneDrive- Error migrating \n",
      "\n",
      "Deposit Edge Account Unlock\n",
      "Deposit Edge Account Unlock \n",
      "\n",
      "MFA Authentication Loop - Unable to access email\n",
      "MFA Authentication Loop- Unable to access email \n",
      "\n",
      "Beta report ran out of paper. Needs a restart.\n",
      "Beta report ran out of paper. Needs a restart. \n",
      "\n",
      "Laptop not charging on Docking Station\n",
      "Laptop not charging on Docking Station \n",
      "\n",
      "Mac not connecting to Guest wifi\n",
      "Mac not connecting to Guest wifi \n",
      "\n",
      "RJ Edgerly needs his Outlook inbox restored\n",
      "<PERSON> <PERSON> needs his Outlook inbox restored \n",
      "\n",
      "Hello. My name is spelled incorrectly on the DocuSign application. It is Veronica Fitzpatrick, some letters are all flipped around  backwards and I was hoping to have that fixed!\n",
      "Hello. My name is spelled incorrectly on the DocuSign application. It is <PERSON> <PERSON>, some letters are all flipped around   backwards and I was hoping to have that fixed! \n",
      "\n",
      "Custom example: Bryce Townsend tried to run the program 6 times earlier to no avail. Can you please check? It’s costing us $2 per day! A million thanks. You are 100% awesome.\n",
      "Custom example: <PERSON> <PERSON> tried to run the program <CARDINAL> times earlier to no avail. Can you please check? It ’s costing us $ <MONEY> per day! <CARDINAL> <CARDINAL> thanks. You are <PERCENT> <PERCENT> awesome. \n",
      "\n",
      "Custom example: Aditya Patel needs a new machine, so does Emilio Hernandez.\n",
      "Custom example: <PERSON> <PERSON> needs a new machine, so does <PERSON> <PERSON>. \n",
      "\n",
      "Custom example: Stanislav Oliynyk needs a new machine, so does Takeshi Ueda\n",
      "Custom example: <PERSON> <PERSON> needs a new machine, so does <PERSON> <PERSON> \n",
      "\n",
      "Custom example: Parasol needs to have her new workstation set up – please follow up. Thanks.\n",
      "Custom example: <PERSON> needs to have her new workstation set up– please follow up. Thanks. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_series:\n",
    "    print(doc)\n",
    "    filtered_string = \"\"\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in ['PERSON', 'MONEY', 'CARDINAL', 'QUANTITY', 'PERCENT']:\n",
    "            new_token = \" <{}>\".format(token.ent_type_)\n",
    "        # elif token.pos_ in ['PROPN']:\n",
    "        #     new_token = \" <PROPN>\"\n",
    "        # elif token.pos_ in ['PROPN', 'NUM']:\n",
    "        #     new_token = \" <{}>\".format(token.ent_type_)\n",
    "        elif token.pos_ == \"PUNCT\":\n",
    "            new_token = token.text\n",
    "        else:\n",
    "            new_token = \" {}\".format(token.text)\n",
    "        filtered_string += new_token\n",
    "    filtered_string = filtered_string[1:]\n",
    "    print(filtered_string, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.092695770Z",
     "start_time": "2023-07-12T03:18:49.088775400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Check NER results.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Dictionary accumulator for entities based on entity type\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ORG': 2, 'PERSON': 9, 'PRODUCT': 1, 'CARDINAL': 2, 'MONEY': 1, 'PERCENT': 1}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict = {}\n",
    "def count_ent(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in ent_dict:\n",
    "            ent_dict[ent.label_] = 1\n",
    "        else:\n",
    "            ent_dict[ent.label_]+=1\n",
    "doc_series.apply(count_ent)\n",
    "ent_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.126418191Z",
     "start_time": "2023-07-12T03:18:49.096549758Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "print(nlp.get_pipe(\"ner\").labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.148172225Z",
     "start_time": "2023-07-12T03:18:49.101049027Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### PERSON.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Brittany Tyler', 1),\n ('RJ Edgerly', 1),\n ('Veronica Fitzpatrick', 1),\n ('Bryce Townsend', 1),\n ('Aditya Patel', 1),\n ('Emilio Hernandez', 1),\n ('Stanislav Oliynyk', 1),\n ('Takeshi Ueda', 1),\n ('Parasol', 1)]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict = {}\n",
    "def count_person(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            if ent.text not in ent_dict:\n",
    "                ent_dict[ent.text]=1\n",
    "            else:\n",
    "                ent_dict[ent.text]+=1\n",
    "doc_series.apply(count_person)\n",
    "sorted(ent_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.148582904Z",
     "start_time": "2023-07-12T03:18:49.142594925Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "&nbsp;\n",
    "#### Save out above entity list + counts as a pd.Sereies() object.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "output_dir = r'./PII'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.148747287Z",
     "start_time": "2023-07-12T03:18:49.142831706Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "ner_obj = sorted(ent_dict.items(), key=lambda x: x[1], reverse=True) # specify which dict to save\n",
    "ner_obj = pd.Series(ner_obj)\n",
    "ner_obj.to_csv(output_dir + 'ner_obj.csv', sep=';', encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T03:18:49.148974873Z",
     "start_time": "2023-07-12T03:18:49.143009065Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
