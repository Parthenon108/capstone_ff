{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:47.390604371Z",
     "start_time": "2023-07-12T02:00:47.347990702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'./DatabaseTableUpload/Appendix_A_Capstone_DataSharingProposal.xlsx', sheet_name='A.25_ServiceNow_Incidents') # provide path for single .csv file\n",
    "# directory = r'C:\\Users\\RJ\\Downloads\\2021_1021_re_esg\\\\' # or provide a directory that contains a collection of .csv/.xlsx files:\n",
    "\n",
    "start_time = datetime.now()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:47.609526743Z",
     "start_time": "2023-07-12T02:00:47.527171997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# source_type = r'csv' # can be: directory, csv, or xlsx\n",
    "# if source_type == 'directory':\n",
    "#     df = pd.concat(map(lambda file: pd.read_csv(file, sep= \";\", encoding = \"utf-8-sig\", low_memory=False), \\\n",
    "#                        glob.glob(os.path.join('', directory + '*.csv'))))\n",
    "# elif source_type == r'csv':\n",
    "#     df = pd.read_csv(csv, sep=';', low_memory=False)\n",
    "# elif source_type == r'xlsx':\n",
    "#     sheet_name = 1\n",
    "#     df = pd.read_excel(path, sheet_name=sheet_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:47.686798709Z",
     "start_time": "2023-07-12T02:00:47.686545118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "output_dir = r'./PII'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:47.989107625Z",
     "start_time": "2023-07-12T02:00:47.984416479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Columns: 118 entries, parent to category\n",
      "dtypes: float64(72), object(46)\n",
      "memory usage: 12.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:48.326839693Z",
     "start_time": "2023-07-12T02:00:48.322633842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent\n",
      "caused_by\n",
      "watch_list\n",
      "u_browser_type\n",
      "u_swap\n",
      "upon_reject\n",
      "sys_updated_on\n",
      "origin_table\n",
      "skills\n",
      "u_gl_code\n",
      "number\n",
      "u_moniker\n",
      "state\n",
      "knowledge\n",
      "order\n",
      "contract\n",
      "impact\n",
      "active\n",
      "priority\n",
      "sys_domain_path\n",
      "u_asset_substatus\n",
      "business_duration\n",
      "group_list\n",
      "approval_set\n",
      "u_public_pc\n",
      "needs_attention\n",
      "universal_request\n",
      "short_description\n",
      "correlation_display\n",
      "u_error_code\n",
      "work_start\n",
      "additional_assignee_list\n",
      "u_requestor\n",
      "notify\n",
      "service_offering\n",
      "sys_class_name\n",
      "closed_by\n",
      "follow_up\n",
      "parent_incident\n",
      "reopened_by\n",
      "u_hardware_swap\n",
      "reassignment_count\n",
      "u_end_of_lifecycle\n",
      "assigned_to\n",
      "sla_due\n",
      "comments_and_work_notes\n",
      "u_actual_resolution_time\n",
      "u_affect_asset\n",
      "u_replacement_asset\n",
      "u_cause_code\n",
      "escalation\n",
      "upon_approval\n",
      "correlation_id\n",
      "u_location\n",
      "made_sla\n",
      "u_browsing_data_cleared\n",
      "u_paging_response\n",
      "child_incidents\n",
      "task_effective_number\n",
      "resolved_by\n",
      "sys_updated_by\n",
      "opened_by\n",
      "user_input\n",
      "sys_created_on\n",
      "sys_domain\n",
      "route_reason\n",
      "calendar_stc\n",
      "closed_at\n",
      "u_error_code_account_alerts\n",
      "u_windows_version\n",
      "business_service\n",
      "business_impact\n",
      "rfc\n",
      "time_worked\n",
      "expected_start\n",
      "opened_at\n",
      "work_end\n",
      "caller_id\n",
      "reopened_time\n",
      "resolved_at\n",
      "u_client\n",
      "subcategory\n",
      "work_notes\n",
      "close_code\n",
      "assignment_group\n",
      "u_next_update_time\n",
      "business_stc\n",
      "u_yodlee_id\n",
      "cause\n",
      "description\n",
      "u_vendor_ticket\n",
      "origin_id\n",
      "calendar_duration\n",
      "close_notes\n",
      "u_stockroom\n",
      "sys_id\n",
      "contact_type\n",
      "u_actual_start_time\n",
      "incident_state\n",
      "urgency\n",
      "problem_id\n",
      "company\n",
      "u_factset_ticket_number\n",
      "activity_due\n",
      "action_status\n",
      "severity\n",
      "comments\n",
      "approval\n",
      "due_date\n",
      "sys_mod_count\n",
      "u_affected_user\n",
      "reopen_count\n",
      "u_scivantave_ticket_number\n",
      "sys_tags\n",
      "u_yodlee_sr_1\n",
      "u_interaction\n",
      "location\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:48.495425347Z",
     "start_time": "2023-07-12T02:00:48.453026438Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Named Entity Recognition (NER)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sizes: ['sm', 'md', 'lg']<br>\n",
    "Your pipeline must be compatable with your current version of SpaCy.\n",
    "\n",
    "Can download the following on Conda (base) environment:\n",
    "`pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_[SIZE]-[VERSION]/en_core_web_md-[VERSION].tar.gz`\n",
    "\n",
    "Alternatively, in Python:\n",
    "`python -m spacy download en_core_web_sm`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Instantiate a Tokenizer with the default settings for English, including punctuation rules and exceptions.\n",
    "tokenizer = nlp.tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:48.905389423Z",
     "start_time": "2023-07-12T02:00:48.808220062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Assign SpaCy `en_core_web_[SIZE]` as `nlp`.\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "ner = nlp.get_pipe('ner')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:51.389566719Z",
     "start_time": "2023-07-12T02:00:48.998447654Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitney Bowes P2000 Series isn't able to connect with network\n",
      "Pitney PROPN compound\n",
      "Bowes PROPN compound\n",
      "P2000 PROPN compound\n",
      "Series PROPN nsubj\n",
      "is AUX ROOT\n",
      "n't PART neg\n",
      "able ADJ acomp\n",
      "to PART aux\n",
      "connect VERB xcomp\n",
      "with ADP prep\n",
      "network NOUN pobj\n"
     ]
    }
   ],
   "source": [
    "# Example of token generation for the first body of text.\n",
    "doc = nlp(df['short_description'][0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_) # Print: token, POS, syntactic dependency."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:51.474506859Z",
     "start_time": "2023-07-12T02:00:51.391742694Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Create function to add an article's tokens to `doc_list`.\n",
    "# Tokenize one time, then use that object for the subsequent accumulators.\n",
    "# Returns None many times.\n",
    "doc_list = []\n",
    "def to_doc_list(text):\n",
    "    doc_list.append(nlp(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:51.474856704Z",
     "start_time": "2023-07-12T02:00:51.470593355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "0     None\n1     None\n2     None\n3     None\n4     None\n5     None\n6     None\n7     None\n8     None\n9     None\n10    None\n11    None\n12    None\nName: short_description, dtype: object"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes time to generate tokens from each cell's fulltext.\n",
    "df['short_description'].apply(to_doc_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:51.840162259Z",
     "start_time": "2023-07-12T02:00:51.470845470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "0     (Pitney, Bowes, P2000, Series, is, n't, able, ...\n1       (Can, not, connect, to, in, -, office, Desktop)\n2             (Brittany, Tyler, -, Fixed, Income, Desk)\n3     (Break, /, fix, Docking, station, not, providi...\n4     (Baird, TrustDesk, Migration, to, OneDrive, -,...\n5                      (Deposit, Edge, Account, Unlock)\n6     (MFA, Authentication, Loop, -, Unable, to, acc...\n7     (Beta, report, ran, out, of, paper, ., Needs, ...\n8         (Laptop, not, charging, on, Docking, Station)\n9               (Mac, not, connecting, to, Guest, wifi)\n10    (RJ, Edgerly, needs, his, Outlook, inbox, rest...\n11    (Hello, ., My, name, is, spelled, incorrectly,...\n12    (Custom, example, :, Bryce, Townsend, tried, t...\ndtype: object"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign `doc_list` to `doc_series` as a Series object.\n",
    "doc_series = pd.Series(doc_list)\n",
    "doc_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:51.848094567Z",
     "start_time": "2023-07-12T02:00:51.843410857Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitney Bowes P2000 Series isn't able to connect with network\n",
      "Pitney Bowes P2000 Series is n't able to connect with network \n",
      "\n",
      "Cannot connect to in-office Desktop\n",
      "Can not connect to in- office Desktop \n",
      "\n",
      "Brittany Tyler - Fixed Income Desk\n",
      "<PERSON> <PERSON>- Fixed Income Desk \n",
      "\n",
      "Break/fix Docking station not providing monitor display or network\n",
      "Break / fix Docking station not providing monitor display or network \n",
      "\n",
      "Baird TrustDesk Migration to OneDrive - Error migrating \n",
      "Baird TrustDesk Migration to OneDrive- Error migrating \n",
      "\n",
      "Deposit Edge Account Unlock\n",
      "Deposit Edge Account Unlock \n",
      "\n",
      "MFA Authentication Loop - Unable to access email\n",
      "MFA Authentication Loop- Unable to access email \n",
      "\n",
      "Beta report ran out of paper. Needs a restart.\n",
      "Beta report ran out of paper. Needs a restart. \n",
      "\n",
      "Laptop not charging on Docking Station\n",
      "Laptop not charging on Docking Station \n",
      "\n",
      "Mac not connecting to Guest wifi\n",
      "Mac not connecting to Guest wifi \n",
      "\n",
      "RJ Edgerly needs his Outlook inbox restored\n",
      "<PERSON> <PERSON> needs his Outlook inbox restored \n",
      "\n",
      "Hello. My name is spelled incorrectly on the DocuSign application. It is Veronica Fitzpatrick, some letters are all flipped around  backwards and I was hoping to have that fixed!\n",
      "Hello. My name is spelled incorrectly on the DocuSign application. It is <PERSON> <PERSON>, some letters are all flipped around   backwards and I was hoping to have that fixed! \n",
      "\n",
      "Custom example: Bryce Townsend tried to run the program 6 times earlier to no avail. Can you please check? It’s costing us $2 per day! A million thanks. You are 100% awesome.\n",
      "Custom example: <PERSON> <PERSON> tried to run the program <CARDINAL> times earlier to no avail. Can you please check? It ’s costing us $ <MONEY> per day! <CARDINAL> <CARDINAL> thanks. You are <PERCENT> <PERCENT> awesome. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_series:\n",
    "    print(doc)\n",
    "    filtered_string = \"\"\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in ['PERSON', 'MONEY', 'CARDINAL', 'QUANTITY', 'PERCENT']:\n",
    "            new_token = \" <{}>\".format(token.ent_type_)\n",
    "        # elif token.pos_ in ['PROPN']:\n",
    "        #     new_token = \" <PROPN>\"\n",
    "        # elif token.pos_ in ['PROPN', 'NUM']:\n",
    "        #     new_token = \" <{}>\".format(token.ent_type_)\n",
    "        elif token.pos_ == \"PUNCT\":\n",
    "            new_token = token.text\n",
    "        else:\n",
    "            new_token = \" {}\".format(token.text)\n",
    "        filtered_string += new_token\n",
    "    filtered_string = filtered_string[1:]\n",
    "    print(filtered_string, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T02:00:51.864340413Z",
     "start_time": "2023-07-12T02:00:51.847203280Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Check NER for misses/gaps.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Dictionary accumulator for entities based on entity type\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ORG': 2, 'PERSON': 4, 'PRODUCT': 1, 'CARDINAL': 1}"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict = {}\n",
    "def count_ent(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in ent_dict:\n",
    "            ent_dict[ent.label_] = 1\n",
    "        else:\n",
    "            ent_dict[ent.label_]+=1\n",
    "doc_series.apply(count_ent)\n",
    "ent_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T01:59:40.979779971Z",
     "start_time": "2023-07-12T01:59:40.974998120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "print(nlp.get_pipe(\"ner\").labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T01:59:43.481842807Z",
     "start_time": "2023-07-12T01:59:43.477658403Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### PERSON.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Brittany Tyler', 1),\n ('RJ Edgerly', 1),\n ('Veronica Fitzpatrick', 1),\n ('Bryce Townsend', 1)]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_dict = {}\n",
    "def count_person(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            if ent.text not in person_dict:\n",
    "                person_dict[ent.text]=1\n",
    "            else:\n",
    "                person_dict[ent.text]+=1\n",
    "doc_series.apply(count_person)\n",
    "sorted(person_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T01:59:45.052239555Z",
     "start_time": "2023-07-12T01:59:45.048361298Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### ORG (organization).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Pitney Bowes P2000 Series', 1), ('DocuSign', 1)]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_dict = {}\n",
    "def count_org(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'ORG':\n",
    "            if ent.text not in org_dict:\n",
    "                org_dict[ent.text]=1\n",
    "            else:\n",
    "                org_dict[ent.text]+=1\n",
    "doc_series.apply(count_org)\n",
    "sorted(org_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T01:50:30.243727127Z",
     "start_time": "2023-07-12T01:50:30.200737534Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "___\n",
    "\n",
    "&nbsp;\n",
    "#### Save out any of the above as a Series object\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ner_obj = sorted(org_dict.items(), key=lambda x: x[1], reverse=True) # specify which dict to save\n",
    "ner_obj = pd.Series(ner_obj)\n",
    "ner_obj\n",
    "# ner_obj.to_csv(output_dir+'ner_obj.csv', sep=';', encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "***\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
