{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.275053929Z",
     "start_time": "2023-07-02T18:09:11.191100916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'./Appendix_A_Capstone_DataSharingProposal.xlsx', sheet_name='A.25_ServiceNow_Incidents') # provide path for single .csv file\n",
    "# directory = r'C:\\Users\\RJ\\Downloads\\2021_1021_re_esg\\\\' # or provide a directory that contains a collection of .csv/.xlsx files:\n",
    "\n",
    "start_time = datetime.now()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.548775863Z",
     "start_time": "2023-07-02T18:09:11.200586653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# source_type = r'csv' # can be: directory, csv, or xlsx\n",
    "# if source_type == 'directory':\n",
    "#     df = pd.concat(map(lambda file: pd.read_csv(file, sep= \";\", encoding = \"utf-8-sig\", low_memory=False), \\\n",
    "#                        glob.glob(os.path.join('', directory + '*.csv'))))\n",
    "# elif source_type == r'csv':\n",
    "#     df = pd.read_csv(csv, sep=';', low_memory=False)\n",
    "# elif source_type == r'xlsx':\n",
    "#     sheet_name = 1\n",
    "#     df = pd.read_excel(path, sheet_name=sheet_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.549330588Z",
     "start_time": "2023-07-02T18:09:11.330294455Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "output_dir = r'./output'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.549549625Z",
     "start_time": "2023-07-02T18:09:11.331502188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Columns: 118 entries, parent to category\n",
      "dtypes: bool(9), float64(58), int64(14), object(37)\n",
      "memory usage: 10.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.549801289Z",
     "start_time": "2023-07-02T18:09:11.333154482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent\n",
      "caused_by\n",
      "watch_list\n",
      "u_browser_type\n",
      "u_swap\n",
      "upon_reject\n",
      "sys_updated_on\n",
      "origin_table\n",
      "skills\n",
      "u_gl_code\n",
      "number\n",
      "u_moniker\n",
      "state\n",
      "knowledge\n",
      "order\n",
      "contract\n",
      "impact\n",
      "active\n",
      "priority\n",
      "sys_domain_path\n",
      "u_asset_substatus\n",
      "business_duration\n",
      "group_list\n",
      "approval_set\n",
      "u_public_pc\n",
      "needs_attention\n",
      "universal_request\n",
      "short_description\n",
      "correlation_display\n",
      "u_error_code\n",
      "work_start\n",
      "additional_assignee_list\n",
      "u_requestor\n",
      "notify\n",
      "service_offering\n",
      "sys_class_name\n",
      "closed_by\n",
      "follow_up\n",
      "parent_incident\n",
      "reopened_by\n",
      "u_hardware_swap\n",
      "reassignment_count\n",
      "u_end_of_lifecycle\n",
      "assigned_to\n",
      "sla_due\n",
      "comments_and_work_notes\n",
      "u_actual_resolution_time\n",
      "u_affect_asset\n",
      "u_replacement_asset\n",
      "u_cause_code\n",
      "escalation\n",
      "upon_approval\n",
      "correlation_id\n",
      "u_location\n",
      "made_sla\n",
      "u_browsing_data_cleared\n",
      "u_paging_response\n",
      "child_incidents\n",
      "task_effective_number\n",
      "resolved_by\n",
      "sys_updated_by\n",
      "opened_by\n",
      "user_input\n",
      "sys_created_on\n",
      "sys_domain\n",
      "route_reason\n",
      "calendar_stc\n",
      "closed_at\n",
      "u_error_code_account_alerts\n",
      "u_windows_version\n",
      "business_service\n",
      "business_impact\n",
      "rfc\n",
      "time_worked\n",
      "expected_start\n",
      "opened_at\n",
      "work_end\n",
      "caller_id\n",
      "reopened_time\n",
      "resolved_at\n",
      "u_client\n",
      "subcategory\n",
      "work_notes\n",
      "close_code\n",
      "assignment_group\n",
      "u_next_update_time\n",
      "business_stc\n",
      "u_yodlee_id\n",
      "cause\n",
      "description\n",
      "u_vendor_ticket\n",
      "origin_id\n",
      "calendar_duration\n",
      "close_notes\n",
      "u_stockroom\n",
      "sys_id\n",
      "contact_type\n",
      "u_actual_start_time\n",
      "incident_state\n",
      "urgency\n",
      "problem_id\n",
      "company\n",
      "u_factset_ticket_number\n",
      "activity_due\n",
      "action_status\n",
      "severity\n",
      "comments\n",
      "approval\n",
      "due_date\n",
      "sys_mod_count\n",
      "u_affected_user\n",
      "reopen_count\n",
      "u_scivantave_ticket_number\n",
      "sys_tags\n",
      "u_yodlee_sr_1\n",
      "u_interaction\n",
      "location\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.550674915Z",
     "start_time": "2023-07-02T18:09:11.339522598Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Named Entity Recognition (NER)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sizes: ['sm', 'md', 'lg']<br>\n",
    "Your pipeline must be compatable with your current version of SpaCy.\n",
    "\n",
    "Can download the following on Conda (base) environment:\n",
    "`pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_[SIZE]-[VERSION]/en_core_web_md-[VERSION].tar.gz`\n",
    "\n",
    "Alternatively, in Python:\n",
    "`python -m spacy download en_core_web_sm`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Instantiate a Tokenizer with the default settings for English, including punctuation rules and exceptions.\n",
    "tokenizer = nlp.tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.555191849Z",
     "start_time": "2023-07-02T18:09:11.396944973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Assign SpaCy `en_core_web_[SIZE]` as `nlp`.\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:11.939804590Z",
     "start_time": "2023-07-02T18:09:11.441616741Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not getting a DHCP address from server\n",
      "Send Pro P2000\n",
      "MAC: C400AD3CDBE9\n",
      "\n",
      "PB Tech Cell #: <PHONE NUMBER> - <NAME>\n",
      "x4049\n",
      "not PART neg\n",
      "getting VERB ROOT\n",
      "a DET det\n",
      "DHCP PROPN compound\n",
      "address NOUN dobj\n",
      "from ADP prep\n",
      "server NOUN pobj\n",
      "\n",
      " SPACE dep\n",
      "Send VERB acl\n",
      "Pro PROPN nmod\n",
      "P2000 PROPN nmod\n",
      "\n",
      " SPACE dep\n",
      "MAC PROPN dobj\n",
      ": PUNCT punct\n",
      "C400AD3CDBE9 ADJ amod\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "PB PROPN compound\n",
      "Tech PROPN compound\n",
      "Cell PROPN dep\n",
      "# NOUN advmod\n",
      ": PUNCT punct\n",
      "< X punct\n",
      "PHONE NOUN compound\n",
      "NUMBER PROPN dep\n",
      "> X punct\n",
      "- PUNCT punct\n",
      "< X nmod\n",
      "NAME PROPN appos\n",
      "> PUNCT punct\n",
      "\n",
      " SPACE dep\n",
      "x4049 NOUN punct\n"
     ]
    }
   ],
   "source": [
    "# Example of token generation for the first body of text.\n",
    "doc = nlp(df['description'][0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_) # Print: token, POS, syntactic dependency."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.011556940Z",
     "start_time": "2023-07-02T18:09:11.855422257Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Create function to add an article's tokens to `doc_list`.\n",
    "# Tokenize one time, then use that object for the subsequent accumulators.\n",
    "# Returns None many times.\n",
    "doc_list = []\n",
    "def to_doc_list(text):\n",
    "    doc_list.append(nlp(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.011869159Z",
     "start_time": "2023-07-02T18:09:11.869939439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "0     None\n1     None\n2     None\n3     None\n4     None\n5     None\n6     None\n7     None\n8     None\n9     None\n10    None\n11    None\nName: description, dtype: object"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes time to generate tokens from each cell's fulltext.\n",
    "df['description'].apply(to_doc_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.178779696Z",
     "start_time": "2023-07-02T18:09:11.874957361Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0     (not, getting, a, DHCP, address, from, server,...\n1       (Can, not, connect, to, in, -, office, Desktop)\n2     (received, from, :, <, EMAIL, >, \\n\\n, Good, m...\n3     (Docking, station, not, providing, monitor, di...\n4     (Baird, TrustDesk, Migration, to, OneDrive, -,...\n5                      (Deposit, Edge, Account, Unlock)\n6     (User, is, receiving, a, password, prompt, for...\n7     (Beta, report, ran, out, of, paper, ., Needs, ...\n8         (Laptop, not, charging, on, Docking, Station)\n9               (Mac, not, connecting, to, Guest, wifi)\n10    (<, NAME, >, needs, his, Outlook, inbox, resto...\n11    (Hello, ., My, name, is, spelled, incorrectly,...\ndtype: object"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign `doc_list` to `doc_series` as a Series object.\n",
    "doc_series = pd.Series(doc_list)\n",
    "doc_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.179186123Z",
     "start_time": "2023-07-02T18:09:11.961699410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not getting a <> address from server \n",
      " Send <> <> \n",
      " <ORG>: C400AD3CDBE9 \n",
      "\n",
      " <> <> <> #: < PHONE <> >- < <>> \n",
      " x4049\n",
      "Can not connect to in- office Desktop\n",
      "received from: < <> > \n",
      "\n",
      " Good morning, \n",
      "\n",
      " If possible, please could someone come and help < NAME > with his displays- he is using <CARDINAL> of the <> <> desks upstairs. \n",
      "\n",
      " Thanks \n",
      "\n",
      " < <> > \n",
      "\n",
      " <> <> \n",
      " <> <> \n",
      " <> <> <> \n",
      "( o)   +44 <MONEY> <CARDINAL> <PERSON> \n",
      " <>> |   bairdeurope.com \n",
      "\n",
      "[ Graphical user interface     <> automatically generated]<http://www.rwbaird.com/ >\n",
      "Docking station not providing monitor display or network \n",
      "\n",
      " < <> > is borrowing another docking station. < <> > <> will not light up whatsoever when plugged in. \n",
      "\n",
      "<ORG> <ORG> <ORG> to <ORG>- Error migrating \n",
      " There was an error verifying your <ORG> migration, please do not try to Use <GPE> or <> and contact the <> <>.\n",
      "<> <> <> <>\n",
      "<> is receiving a password prompt for their <DATE> day re - approval for email access. <ORG> authenticator is looping and will not authenticate. \n",
      " Cell: < PHONE NUMBER >\n",
      "Beta report ran out of paper. Needs a restart. \n",
      " <>\n",
      "Laptop not charging on <> <>\n",
      "<> not connecting to <PERSON> <>\n",
      "< <>> needs his <PRODUCT> inbox restored \n",
      " <> was accidentally deleted\n",
      "Hello. My name is spelled incorrectly on the <ORG> application. It is < <>>, some letters are all flipped around   backwards and I was hoping to have that fixed!\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_series:\n",
    "    filtered_string = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ in ['PROPN', 'NUM']:\n",
    "            new_token = \" <{}>\".format(token.ent_type_)\n",
    "        elif token.pos_ == \"PUNCT\":\n",
    "            new_token = token.text\n",
    "        else:\n",
    "            new_token = \" {}\".format(token.text)\n",
    "        filtered_string += new_token\n",
    "    filtered_string = filtered_string[1:]\n",
    "    print(filtered_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.179694296Z",
     "start_time": "2023-07-02T18:09:12.005813974Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Dictionary accumulator for entities based on entity type\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ORG': 7,\n 'CARDINAL': 3,\n 'TIME': 1,\n 'MONEY': 1,\n 'PERSON': 2,\n 'GPE': 1,\n 'DATE': 1,\n 'PRODUCT': 1}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict = {}\n",
    "def count_ent(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in ent_dict:\n",
    "            ent_dict[ent.label_] = 1\n",
    "        else:\n",
    "            ent_dict[ent.label_]+=1\n",
    "doc_series.apply(count_ent)\n",
    "ent_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.179853062Z",
     "start_time": "2023-07-02T18:09:12.006305616Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Check NER for misses/gaps.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### PERSON.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "[('8239', 1), ('Guest', 1)]"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_dict = {}\n",
    "def count_person(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            if ent.text not in person_dict:\n",
    "                person_dict[ent.text]=1\n",
    "            else:\n",
    "                person_dict[ent.text]+=1\n",
    "doc_series.apply(count_person)\n",
    "sorted(person_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.180135733Z",
     "start_time": "2023-07-02T18:09:12.006572897Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### GPE (geopolitical entity).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Use Trustdesk', 1)]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpe_dict = {}\n",
    "def count_gpe(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'GPE':\n",
    "            if ent.text not in gpe_dict:\n",
    "                gpe_dict[ent.text]=1\n",
    "            else:\n",
    "                gpe_dict[ent.text]+=1\n",
    "doc_series.apply(count_gpe)\n",
    "sorted(gpe_dict.items(), key=lambda x: x[1], reverse=True)[0:30]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.180352873Z",
     "start_time": "2023-07-02T18:09:12.006788553Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### ORG (organization).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "[('MAC', 1),\n ('+44', 1),\n ('Baird TrustDesk Migration', 1),\n ('OneDrive - Error', 1),\n ('TrustDesk', 1),\n ('MFA', 1),\n ('DocuSign', 1)]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_dict = {}\n",
    "def count_org(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'ORG':\n",
    "            if ent.text not in org_dict:\n",
    "                org_dict[ent.text]=1\n",
    "            else:\n",
    "                org_dict[ent.text]+=1\n",
    "doc_series.apply(count_org)\n",
    "sorted(org_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.180576497Z",
     "start_time": "2023-07-02T18:09:12.007074894Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### FAC (factory).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fac_dict = {}\n",
    "def count_fac(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'FAC':\n",
    "            if ent.text not in fac_dict:\n",
    "                fac_dict[ent.text]=1\n",
    "            else:\n",
    "                fac_dict[ent.text]+=1\n",
    "doc_series.apply(count_fac)\n",
    "sorted(fac_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.180779176Z",
     "start_time": "2023-07-02T18:09:12.007298677Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### TIME.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "[('morning', 1)]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dict = {}\n",
    "def count_time(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'TIME':\n",
    "            if ent.text not in time_dict:\n",
    "                time_dict[ent.text]=1\n",
    "            else:\n",
    "                time_dict[ent.text]+=1\n",
    "doc_series.apply(count_time)\n",
    "sorted(time_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.180997997Z",
     "start_time": "2023-07-02T18:09:12.007514983Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### EVE (event).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_dict = {}\n",
    "def count_event(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'EVENT':\n",
    "            if ent.text not in event_dict:\n",
    "                event_dict[ent.text]=1\n",
    "            else:\n",
    "                event_dict[ent.text]+=1\n",
    "doc_series.apply(count_event)\n",
    "sorted(event_dict.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.182384605Z",
     "start_time": "2023-07-02T18:09:12.007739049Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "___\n",
    "\n",
    "&nbsp;\n",
    "#### Save out any of the above as a Series object\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "0                          (MAC, 1)\n1                          (+44, 1)\n2    (Baird TrustDesk Migration, 1)\n3             (OneDrive - Error, 1)\n4                    (TrustDesk, 1)\n5                          (MFA, 1)\n6                     (DocuSign, 1)\ndtype: object"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_obj = sorted(org_dict.items(), key=lambda x: x[1], reverse=True) # specify which dict to save\n",
    "ner_obj = pd.Series(ner_obj)\n",
    "ner_obj\n",
    "# ner_obj.to_csv(output_dir+'ner_obj.csv', sep=';', encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:09:12.182672645Z",
     "start_time": "2023-07-02T18:09:12.053853998Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "***\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
